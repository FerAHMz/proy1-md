{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8267e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala librerías necesarias\n",
    "%pip install pandas pyreadstat matplotlib scipy seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70b3c54",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Datos - Defunciones Guatemala (2009-2020)\n",
    "## Inciso a: Descripción del Conjunto de Datos\n",
    "\n",
    "Este notebook analiza los datos de defunciones en Guatemala de 2009 a 2020, describiendo:\n",
    "- Número de variables y observaciones\n",
    "- Tipo de cada variable\n",
    "- Estructura general del dataset unificado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba5060",
   "metadata": {},
   "source": [
    "## 1. Importar Librerías Necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0575f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadstat\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Librerías importadas exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0d377",
   "metadata": {},
   "source": [
    "## 2. Cargar y Explorar Archivos .sav Individuales\n",
    "\n",
    "Primero, identificamos todos los archivos .sav disponibles y exploramos su estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eafe2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define la ruta a los datos (subir un nivel desde la carpeta actual)\n",
    "data_path = Path(r'../data/defunciones/sav')\n",
    "\n",
    "# Lista todos los archivos .sav\n",
    "archivos_sav = sorted(list(data_path.glob('*.sav')))\n",
    "\n",
    "print(f\"Total de archivos .sav encontrados: {len(archivos_sav)}\\n\")\n",
    "print(\"Archivos disponibles:\")\n",
    "for i, archivo in enumerate(archivos_sav, 1):\n",
    "    print(f\"{i}. {archivo.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explora un archivo de ejemplo para entender la estructura\n",
    "ejemplo_archivo = archivos_sav[0]\n",
    "print(f\"Cargando archivo de ejemplo: {ejemplo_archivo.name}\\n\")\n",
    "\n",
    "# Carga el archivo .sav con metadatos\n",
    "df_ejemplo, meta = pyreadstat.read_sav(str(ejemplo_archivo))\n",
    "\n",
    "print(f\"Dimensiones: {df_ejemplo.shape[0]} observaciones x {df_ejemplo.shape[1]} variables\")\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "display(df_ejemplo.head())\n",
    "\n",
    "print(f\"\\nInformación del DataFrame:\")\n",
    "display(df_ejemplo.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f9277",
   "metadata": {},
   "source": [
    "## 3. Analizar Consistencia de Variables entre Años\n",
    "\n",
    "Verificamos si las variables son consistentes entre todos los años o si hay cambios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga todos los archivos y revisar estructura\n",
    "estructura_por_anio = {}\n",
    "\n",
    "for archivo in archivos_sav:\n",
    "    year = archivo.stem.split('-')[0]  # Extrae el año del nombre del archivo\n",
    "    df_temp, meta_temp = pyreadstat.read_sav(str(archivo))\n",
    "    \n",
    "    estructura_por_anio[year] = {\n",
    "        'num_obs': df_temp.shape[0],\n",
    "        'num_vars': df_temp.shape[1],\n",
    "        'columnas': list(df_temp.columns),\n",
    "        'tipos': df_temp.dtypes.to_dict()\n",
    "    }\n",
    "\n",
    "# Crea DataFrame de resumen\n",
    "resumen_estructura = pd.DataFrame({\n",
    "    'Año': list(estructura_por_anio.keys()),\n",
    "    'Observaciones': [estructura_por_anio[y]['num_obs'] for y in estructura_por_anio.keys()],\n",
    "    'Variables': [estructura_por_anio[y]['num_vars'] for y in estructura_por_anio.keys()]\n",
    "})\n",
    "\n",
    "print(\"Resumen de estructura por año:\")\n",
    "display(resumen_estructura)\n",
    "\n",
    "# Verifica consistencia de columnas\n",
    "todas_columnas = [set(estructura_por_anio[y]['columnas']) for y in estructura_por_anio.keys()]\n",
    "columnas_comunes = set.intersection(*todas_columnas)\n",
    "columnas_todas = set.union(*todas_columnas)\n",
    "\n",
    "print(f\"\\nTotal de columnas únicas en todos los archivos: {len(columnas_todas)}\")\n",
    "print(f\"Columnas comunes a todos los años: {len(columnas_comunes)}\")\n",
    "print(f\"Columnas que varían entre años: {len(columnas_todas - columnas_comunes)}\")\n",
    "\n",
    "if columnas_todas != columnas_comunes:\n",
    "    print(\"\\n Las columnas NO son idénticas en todos los años. Habrá que manejar diferencias al unificar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df89fec4",
   "metadata": {},
   "source": [
    "## 4. Unificar Datos de Todos los Años\n",
    "\n",
    "Como necesitamos trabajar con más de 10 años de datos (según las instrucciones), procedemos a unificar todos los archivos en un solo DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225e53d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unifica todos los archivos\n",
    "dataframes = []\n",
    "metadatos = {}\n",
    "\n",
    "for archivo in archivos_sav:\n",
    "    year = archivo.stem.split('-')[0]\n",
    "    print(f\"Cargando: {archivo.name}...\")\n",
    "    \n",
    "    df_temp, meta_temp = pyreadstat.read_sav(str(archivo))\n",
    "    \n",
    "    # Agrega columna de año\n",
    "    df_temp['ANIO'] = int(year)\n",
    "    \n",
    "    dataframes.append(df_temp)\n",
    "    metadatos[year] = meta_temp\n",
    "\n",
    "# Concatena todos los DataFrames\n",
    "df_unificado = pd.concat(dataframes, axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "print(f\"\\n Datos unificados exitosamente!\")\n",
    "print(f\"Total de observaciones: {df_unificado.shape[0]:,}\")\n",
    "print(f\"Total de variables: {df_unificado.shape[1]:,}\")\n",
    "print(f\"Años incluidos: {sorted(df_unificado['ANIO'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51679b5f",
   "metadata": {},
   "source": [
    "## 5. Conteo de Variables y Observaciones\n",
    "\n",
    "Resumen del conjunto de datos unificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33046e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen por año\n",
    "observaciones_por_anio = df_unificado.groupby('ANIO').size().reset_index(name='Observaciones')\n",
    "print(\"Distribución de observaciones por año:\")\n",
    "display(observaciones_por_anio)\n",
    "\n",
    "# Estadísticas generales\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"RESUMEN DEL CONJUNTO DE DATOS UNIFICADO\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total de observaciones (registros): {df_unificado.shape[0]:,}\")\n",
    "print(f\"Total de variables (columnas): {df_unificado.shape[1]:,}\")\n",
    "print(f\"Período cubierto: {df_unificado['ANIO'].min()} - {df_unificado['ANIO'].max()}\")\n",
    "print(f\"Años de datos: {df_unificado['ANIO'].nunique()} años\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f6476e",
   "metadata": {},
   "source": [
    "## 6. Clasificación de Tipos de Variables\n",
    "\n",
    "Analizamos cada variable para clasificarla como numérica (continua/discreta) o categórica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e126342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasifica variables según teoría estadística\n",
    "# Categóricas: Nominales (sin orden) y Ordinales (con orden)\n",
    "# Numéricas: Continuas (cualquier valor) y Discretas (valores contables)\n",
    "\n",
    "clasificacion_vars = []\n",
    "\n",
    "# Define variables que son categóricas aunque estén codificadas como números\n",
    "variables_categoricas_codificadas = {\n",
    "    'Sexo': 'Categórica Nominal',  # 1, 2 pero sin orden intrínseco\n",
    "    'Depreg': 'Categórica Nominal',  # Códigos de departamentos son categorías\n",
    "    'Depocu': 'Categórica Nominal',\n",
    "    'Areag': 'Categórica Nominal',  # Área geográfica (urbano/rural)\n",
    "    'Puedif': 'Categórica Nominal',  # Pueblo de pertenencia\n",
    "    'Pnadif': 'Categórica Nominal',  # País de nacimiento\n",
    "    'Dnadif': 'Categórica Nominal',  # Departamento de nacimiento\n",
    "    'Nacdif': 'Categórica Nominal',  # Nacionalidad\n",
    "    'Predif': 'Categórica Nominal',  # País de residencia\n",
    "    'Dredif': 'Categórica Nominal',  # Departamento de residencia\n",
    "    'Ocur': 'Categórica Nominal',  # Sitio de ocurrencia\n",
    "    'Getdif': 'Categórica Nominal',  # Grupo étnico\n",
    "}\n",
    "\n",
    "# Variables ordinales (tienen orden lógico)\n",
    "variables_ordinales = {\n",
    "    'Escodif': 'Categórica Ordinal',  # Escolaridad del difunto(a) - tiene orden: ninguno, primaria, secundaria, etc.\n",
    "    'Ecidif': 'Categórica Ordinal',  # Estado civil del difunto(a) - puede tener orden lógico\n",
    "    'Perdif': 'Categórica Ordinal',  # Periodo de edad del difunto(a) - orden: horas, días, meses, años\n",
    "    'Asist': 'Categórica Ordinal',  # Asistencia recibida - puede tener orden según nivel de atención\n",
    "    'Cerdef': 'Categórica Ordinal',  # Quien certifica - puede tener orden según nivel de autoridad\n",
    "}\n",
    "\n",
    "for columna in df_unificado.columns:\n",
    "    dtype = df_unificado[columna].dtype\n",
    "    num_unicos = df_unificado[columna].nunique()\n",
    "    valores_ejemplo = df_unificado[columna].dropna().head(3).tolist()\n",
    "    \n",
    "    # Clasifica tipo de variable\n",
    "    if columna in variables_categoricas_codificadas:\n",
    "        tipo_var = variables_categoricas_codificadas[columna]\n",
    "    elif columna in variables_ordinales:\n",
    "        tipo_var = variables_ordinales[columna]\n",
    "    elif dtype in ['int64', 'float64']:\n",
    "        # Numéricas\n",
    "        if num_unicos <= 20:\n",
    "            tipo_var = 'Numérica Discreta'\n",
    "        else:\n",
    "            tipo_var = 'Numérica Continua'\n",
    "    else:\n",
    "        # Categóricas (tipo object/string)\n",
    "        col_lower = columna.lower()\n",
    "        if any(keyword in col_lower for keyword in ['escol', 'nivel', 'grado', 'civil']):\n",
    "            tipo_var = 'Categórica Ordinal'\n",
    "        else:\n",
    "            tipo_var = 'Categórica Nominal'\n",
    "    \n",
    "    clasificacion_vars.append({\n",
    "        'Variable': columna,\n",
    "        'Tipo_Dato': str(dtype),\n",
    "        'Tipo_Variable': tipo_var,\n",
    "        'Valores_Únicos': num_unicos,\n",
    "        'Ejemplo_Valores': str(valores_ejemplo[:3])\n",
    "    })\n",
    "\n",
    "df_clasificacion = pd.DataFrame(clasificacion_vars)\n",
    "\n",
    "# Muestra resumen\n",
    "print(\"=\"*80)\n",
    "print(\"CLASIFICACIÓN DE VARIABLES (SEGÚN TEORÍA ESTADÍSTICA)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nResumen por tipo de variable:\")\n",
    "print(df_clasificacion['Tipo_Variable'].value_counts().sort_index())\n",
    "print(f\"\\nTotal de variables: {len(df_clasificacion)}\")\n",
    "\n",
    "# Desglose por categoría\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VARIABLES CATEGÓRICAS NOMINALES:\")\n",
    "print(\"-\"*80)\n",
    "nominales = df_clasificacion[df_clasificacion['Tipo_Variable'] == 'Categórica Nominal']\n",
    "print(f\"Total: {len(nominales)} variables\")\n",
    "print(\"(Sin orden intrínseco: ej. departamento, municipio, sexo)\")\n",
    "if len(nominales) > 0:\n",
    "    for var in nominales['Variable'].tolist():\n",
    "        print(f\"  • {var}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VARIABLES CATEGÓRICAS ORDINALES:\")\n",
    "print(\"-\"*80)\n",
    "ordinales = df_clasificacion[df_clasificacion['Tipo_Variable'] == 'Categórica Ordinal']\n",
    "print(f\"Total: {len(ordinales)} variables\")\n",
    "print(\"(Con orden lógico: ej. escolaridad, estado civil)\")\n",
    "if len(ordinales) > 0:\n",
    "    for var in ordinales['Variable'].tolist():\n",
    "        print(f\"  • {var}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VARIABLES NUMÉRICAS CONTINUAS:\")\n",
    "print(\"-\"*80)\n",
    "continuas = df_clasificacion[df_clasificacion['Tipo_Variable'] == 'Numérica Continua']\n",
    "print(f\"Total: {len(continuas)} variables\")\n",
    "print(\"(Pueden tomar cualquier valor en un rango: ej. edad exacta)\")\n",
    "if len(continuas) > 0 and len(continuas) <= 15:\n",
    "    for var in continuas['Variable'].tolist():\n",
    "        print(f\"  • {var}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VARIABLES NUMÉRICAS DISCRETAS:\")\n",
    "print(\"-\"*80)\n",
    "discretas = df_clasificacion[df_clasificacion['Tipo_Variable'] == 'Numérica Discreta']\n",
    "print(f\"Total: {len(discretas)} variables\")\n",
    "print(\"(Valores enteros contables: ej. mes, año, día)\")\n",
    "if len(discretas) > 0 and len(discretas) <= 15:\n",
    "    for var in discretas['Variable'].tolist():\n",
    "        print(f\"  • {var}\")\n",
    "\n",
    "# Muestra tabla completa\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETALLE COMPLETO DE TODAS LAS VARIABLES:\")\n",
    "print(\"=\"*80)\n",
    "display(df_clasificacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91606032",
   "metadata": {},
   "source": [
    "## 7. Tabla de Resumen Completo con Metadatos\n",
    "\n",
    "Generamos una tabla comprehensiva con información detallada de cada variable, incluyendo etiquetas de los archivos SPSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ef8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtiene etiquetas de variables desde los metadatos SPSS\n",
    "meta_ejemplo = metadatos[list(metadatos.keys())[0]]  # Usar metadatos del primer año\n",
    "\n",
    "resumen_completo = []\n",
    "\n",
    "for columna in df_unificado.columns:\n",
    "    # Obtiene etiqueta desde metadatos si existe\n",
    "    etiqueta = meta_ejemplo.column_names_to_labels.get(columna, 'Sin descripción')\n",
    "    \n",
    "    # Información básica\n",
    "    num_missing = df_unificado[columna].isna().sum()\n",
    "    pct_missing = (num_missing / len(df_unificado)) * 100\n",
    "    num_unicos = df_unificado[columna].nunique()\n",
    "    \n",
    "    # Tipo de variable\n",
    "    tipo_fila = df_clasificacion[df_clasificacion['Variable'] == columna]['Tipo_Variable'].values\n",
    "    tipo_var = tipo_fila[0] if len(tipo_fila) > 0 else 'N/A'\n",
    "    \n",
    "    resumen_completo.append({\n",
    "        'Variable': columna,\n",
    "        'Descripción': etiqueta,\n",
    "        'Tipo': tipo_var,\n",
    "        'Tipo_Dato': str(df_unificado[columna].dtype),\n",
    "        'Valores_Únicos': num_unicos,\n",
    "        'Valores_Faltantes': num_missing,\n",
    "        '% Faltantes': f\"{pct_missing:.2f}%\"\n",
    "    })\n",
    "\n",
    "df_resumen = pd.DataFrame(resumen_completo)\n",
    "\n",
    "print(\"TABLA RESUMEN COMPLETA DE VARIABLES\")\n",
    "print(\"=\"*80)\n",
    "display(df_resumen)\n",
    "\n",
    "# Guarda a CSV para referencia\n",
    "df_resumen.to_csv('resumen_variables_defunciones.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"\\n Tabla guardada en: resumen_variables_defunciones.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cf676",
   "metadata": {},
   "source": [
    "## 8. Visualización de la Distribución de Tipos de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6a3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cuenta tipos de variables (usando la clasificación correcta de df_clasificacion)\n",
    "conteo_tipos = df_clasificacion['Tipo_Variable'].value_counts().sort_index()\n",
    "\n",
    "# Crea visualización con un solo gráfico de barras\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Colores para cada tipo de variable\n",
    "colors_dict = {\n",
    "    'Categórica Nominal': '#3498db',\n",
    "    'Categórica Ordinal': '#9b59b6',\n",
    "    'Numérica Continua': '#2ecc71',\n",
    "    'Numérica Discreta': '#f39c12'\n",
    "}\n",
    "colors = [colors_dict.get(tipo, '#95a5a6') for tipo in conteo_tipos.index]\n",
    "\n",
    "# Gráfico de barras horizontales\n",
    "ax.barh(conteo_tipos.index, conteo_tipos.values, color=colors)\n",
    "ax.set_xlabel('Cantidad de Variables', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Tipo de Variable', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Distribución de Tipos de Variables\\n(Clasificación Estadística)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Añade valores en las barras\n",
    "for i, v in enumerate(conteo_tipos.values):\n",
    "    ax.text(v + 0.3, i, str(v), va='center', fontweight='bold', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guarda gráfico - INCISO A\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Resumen estadístico detallado\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN ESTADÍSTICO DE TIPOS DE VARIABLES:\")\n",
    "print(\"=\"*80)\n",
    "for tipo, cantidad in conteo_tipos.items():\n",
    "    porcentaje = (cantidad / len(df_clasificacion)) * 100\n",
    "    print(f\"  • {tipo}: {cantidad} variables ({porcentaje:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETACIÓN:\")\n",
    "print(\"=\"*80)\n",
    "print(\"  • Variables Categóricas Nominales: Sin orden intrínseco\")\n",
    "print(\"    Ejemplos: Departamento, Municipio, Sexo, Causa de muerte\")\n",
    "print(\"\\n  • Variables Categóricas Ordinales: Con orden lógico\")\n",
    "print(\"    Ejemplos: Nivel de escolaridad, Estado civil\")\n",
    "print(\"\\n  • Variables Numéricas Continuas: Pueden tomar cualquier valor en un rango\")\n",
    "print(\"    Ejemplos: Edad exacta, mediciones continuas\")\n",
    "print(\"\\n  • Variables Numéricas Discretas: Valores enteros contables\")\n",
    "print(\"    Ejemplos: Mes, Año, Día, conteos\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4803265",
   "metadata": {},
   "source": [
    "## 9. Análisis de Valores Faltantes\n",
    "\n",
    "Identificamos variables con alta proporción de datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba586cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables con valores faltantes\n",
    "df_missing = df_resumen[df_resumen['Valores_Faltantes'] > 0].sort_values('Valores_Faltantes', ascending=False)\n",
    "\n",
    "print(f\"Variables con valores faltantes: {len(df_missing)} de {len(df_resumen)}\")\n",
    "print(f\"\\nTop 10 variables con más valores faltantes:\")\n",
    "display(df_missing.head(10))\n",
    "\n",
    "# Visualizar\n",
    "if len(df_missing) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    top_missing = df_missing.head(15)\n",
    "    ax.barh(top_missing['Variable'], top_missing['Valores_Faltantes'], color='coral')\n",
    "    ax.set_xlabel('Cantidad de Valores Faltantes', fontsize=12)\n",
    "    ax.set_ylabel('Variable', fontsize=12)\n",
    "    ax.set_title('Top 15 Variables con Más Valores Faltantes', fontsize=14, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Guarda gráfico - INCISO A\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c117156",
   "metadata": {},
   "source": [
    "## Conclusiones del Inciso a\n",
    "\n",
    "### Resumen de hallazgos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd3e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CONCLUSIONES - INCISO A: DESCRIPCIÓN DEL CONJUNTO DE DATOS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(\"1. DIMENSIONES DEL DATASET:\")\n",
    "print(f\"   - Total de observaciones: {df_unificado.shape[0]:,} registros de defunciones\")\n",
    "print(f\"   - Total de variables: {df_unificado.shape[1]} variables\")\n",
    "print(f\"   - Período: {df_unificado['ANIO'].min()}-{df_unificado['ANIO'].max()} ({df_unificado['ANIO'].nunique()} años)\")\n",
    "print()\n",
    "\n",
    "print(\"2. CLASIFICACIÓN DE VARIABLES:\")\n",
    "for tipo, cantidad in df_resumen['Tipo'].value_counts().items():\n",
    "    porcentaje = (cantidad / len(df_resumen)) * 100\n",
    "    print(f\"   - {tipo}: {cantidad} variables ({porcentaje:.1f}%)\")\n",
    "print()\n",
    "\n",
    "print(\"3. CALIDAD DE DATOS:\")\n",
    "total_con_missing = len(df_resumen[df_resumen['Valores_Faltantes'] > 0])\n",
    "pct_con_missing = (total_con_missing / len(df_resumen)) * 100\n",
    "print(f\"   - Variables con datos faltantes: {total_con_missing} ({pct_con_missing:.1f}%)\")\n",
    "print(f\"   - Variables completas: {len(df_resumen) - total_con_missing}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699d4495",
   "metadata": {},
   "source": [
    "# Inciso b: Análisis Estadístico de Variables\n",
    "\n",
    "## Resumen de Variables Numéricas y Pruebas de Normalidad\n",
    "\n",
    "En esta sección analizaremos:\n",
    "- Estadísticas descriptivas de las variables numéricas\n",
    "- Pruebas de normalidad (Shapiro-Wilk, Kolmogorov-Smirnov)\n",
    "- Identificación del tipo de distribución\n",
    "- Tablas de frecuencia para variables categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34400137",
   "metadata": {},
   "source": [
    "## 1. Separar Variables Numéricas y Categóricas\n",
    "\n",
    "Primero identificamos y separamos las variables numéricas de las categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e553ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa variables numéricas y categóricas\n",
    "variables_numericas = df_unificado.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "variables_categoricas = df_unificado.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Variables Numéricas ({len(variables_numericas)}):\")\n",
    "print(variables_numericas)\n",
    "print(f\"\\nVariables Categóricas ({len(variables_categoricas)}):\")\n",
    "print(variables_categoricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd610f2",
   "metadata": {},
   "source": [
    "## 2. Resumen Estadístico de Variables Numéricas\n",
    "\n",
    "Calculamos las estadísticas descriptivas principales para todas las variables numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen estadístico completo de variables numéricas\n",
    "print(\"=\"*100)\n",
    "print(\"RESUMEN ESTADÍSTICO DE VARIABLES NUMÉRICAS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "resumen_estadistico = df_unificado[variables_numericas].describe().T\n",
    "\n",
    "# Añade estadísticas adicionales\n",
    "resumen_estadistico['mediana'] = df_unificado[variables_numericas].median()\n",
    "resumen_estadistico['moda'] = df_unificado[variables_numericas].mode().iloc[0]\n",
    "resumen_estadistico['asimetria'] = df_unificado[variables_numericas].skew()\n",
    "resumen_estadistico['curtosis'] = df_unificado[variables_numericas].kurtosis()\n",
    "resumen_estadistico['missing'] = df_unificado[variables_numericas].isna().sum()\n",
    "resumen_estadistico['missing_%'] = (df_unificado[variables_numericas].isna().sum() / len(df_unificado) * 100).round(2)\n",
    "\n",
    "# Reordena columnas\n",
    "resumen_estadistico = resumen_estadistico[['count', 'mean', 'mediana', 'moda', 'std', 'min', '25%', '50%', '75%', 'max', 'asimetria', 'curtosis', 'missing', 'missing_%']]\n",
    "\n",
    "display(resumen_estadistico)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0473133f",
   "metadata": {},
   "source": [
    "## 3. Pruebas de Normalidad\n",
    "\n",
    "Para evaluar si las variables numéricas siguen una distribución normal, utilizaremos:\n",
    "- **Test de Shapiro-Wilk** (para muestras pequeñas, usaremos una muestra aleatoria)\n",
    "- **Test de Kolmogorov-Smirnov** (para muestras grandes)\n",
    "- **Análisis de asimetría y curtosis**\n",
    "- **Gráficos Q-Q Plot y histogramas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ff772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configura estilo de gráficos\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 6)\n",
    "\n",
    "# Realiza pruebas de normalidad\n",
    "resultados_normalidad = []\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"PRUEBAS DE NORMALIDAD PARA VARIABLES NUMÉRICAS\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\nNota: Usando muestra de 5000 registros para Shapiro-Wilk (limitación del test)\\n\")\n",
    "\n",
    "for variable in variables_numericas:\n",
    "    # Remueve valores nulos\n",
    "    datos_limpios = df_unificado[variable].dropna()\n",
    "    \n",
    "    if len(datos_limpios) > 0:\n",
    "        # Toma muestra para Shapiro-Wilk (máximo 5000 por limitaciones del test)\n",
    "        muestra = datos_limpios.sample(min(5000, len(datos_limpios)), random_state=42)\n",
    "        \n",
    "        # Test de Shapiro-Wilk\n",
    "        if len(muestra) >= 3:\n",
    "            shapiro_stat, shapiro_p = stats.shapiro(muestra)\n",
    "        else:\n",
    "            shapiro_stat, shapiro_p = None, None\n",
    "        \n",
    "        # Test de Kolmogorov-Smirnov\n",
    "        ks_stat, ks_p = stats.kstest(datos_limpios, 'norm', args=(datos_limpios.mean(), datos_limpios.std()))\n",
    "        \n",
    "        # Asimetría y Curtosis\n",
    "        asimetria = datos_limpios.skew()\n",
    "        curtosis = datos_limpios.kurtosis()\n",
    "        \n",
    "        # Clasificación de normalidad\n",
    "        es_normal = (shapiro_p > 0.05 if shapiro_p else False) and (ks_p > 0.05)\n",
    "        \n",
    "        resultados_normalidad.append({\n",
    "            'Variable': variable,\n",
    "            'N': len(datos_limpios),\n",
    "            'Shapiro_W': shapiro_stat,\n",
    "            'Shapiro_p': shapiro_p,\n",
    "            'KS_stat': ks_stat,\n",
    "            'KS_p': ks_p,\n",
    "            'Asimetría': asimetria,\n",
    "            'Curtosis': curtosis,\n",
    "            'Es_Normal': 'Sí' if es_normal else 'No'\n",
    "        })\n",
    "\n",
    "# Crea DataFrame de resultados\n",
    "df_normalidad = pd.DataFrame(resultados_normalidad)\n",
    "\n",
    "# Formatea para mejor visualización\n",
    "df_normalidad_display = df_normalidad.copy()\n",
    "df_normalidad_display['Shapiro_p'] = df_normalidad_display['Shapiro_p'].apply(lambda x: f\"{x:.4e}\" if x is not None else 'N/A')\n",
    "df_normalidad_display['KS_p'] = df_normalidad_display['KS_p'].apply(lambda x: f\"{x:.4e}\")\n",
    "df_normalidad_display['Asimetría'] = df_normalidad_display['Asimetría'].apply(lambda x: f\"{x:.2f}\")\n",
    "df_normalidad_display['Curtosis'] = df_normalidad_display['Curtosis'].apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "display(df_normalidad_display)\n",
    "\n",
    "# Resumen de normalidad\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"RESUMEN DE NORMALIDAD:\")\n",
    "print(f\"{'='*100}\")\n",
    "normal_count = (df_normalidad['Es_Normal'] == 'Sí').sum()\n",
    "no_normal_count = (df_normalidad['Es_Normal'] == 'No').sum()\n",
    "print(f\"Variables que siguen distribución normal: {normal_count} ({normal_count/len(df_normalidad)*100:.1f}%)\")\n",
    "print(f\"Variables que NO siguen distribución normal: {no_normal_count} ({no_normal_count/len(df_normalidad)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7fcb6a",
   "metadata": {},
   "source": [
    "### Interpretación de Asimetría y Curtosis\n",
    "\n",
    "- **Asimetría (Skewness)**:\n",
    "  - = 0: Distribución simétrica\n",
    "  - \\> 0: Cola derecha (sesgo positivo)\n",
    "  - < 0: Cola izquierda (sesgo negativo)\n",
    "  \n",
    "- **Curtosis**:\n",
    "  - = 0: Similar a distribución normal\n",
    "  - \\> 0: Leptocúrtica (colas más pesadas, pico más alto)\n",
    "  - < 0: Platicúrtica (colas más ligeras, pico más bajo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b01b32",
   "metadata": {},
   "source": [
    "## 4. Visualización de Distribuciones - Variables Numéricas Clave\n",
    "\n",
    "Analizaremos gráficamente las variables numéricas más importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bed3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona variables clave para visualización detallada\n",
    "variables_clave = ['Edadif', 'Sexo', 'Mesreg', 'Mesocu', 'Depreg', 'Depocu', 'ANIO']\n",
    "\n",
    "# Define rangos válidos para cada variable (excluir códigos de missing como 999, 888, etc.)\n",
    "rangos_validos = {\n",
    "    'Edadif': (0, 120),      # Edad razonable para humanos\n",
    "    'Sexo': (1, 2),          # 1=Masculino, 2=Femenino\n",
    "    'Mesreg': (1, 12),       # Meses del año\n",
    "    'Mesocu': (1, 12),       # Meses del año\n",
    "    'Depreg': (1, 22),       # Departamentos de Guatemala\n",
    "    'Depocu': (1, 22),       # Departamentos de Guatemala\n",
    "    'ANIO': (2009, 2020)     # Rango de años del estudio\n",
    "}\n",
    "\n",
    "# Filtra solo las que existen en el dataset\n",
    "variables_clave = [v for v in variables_clave if v in df_unificado.columns]\n",
    "\n",
    "print(f\"Analizando {len(variables_clave)} variables clave: {variables_clave}\\n\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Crea subplots para cada variable clave\n",
    "for idx, variable in enumerate(variables_clave, start=1):\n",
    "    datos_originales = df_unificado[variable].dropna()\n",
    "    \n",
    "    if len(datos_originales) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Aplica filtro de rango válido\n",
    "    if variable in rangos_validos:\n",
    "        min_val, max_val = rangos_validos[variable]\n",
    "        datos = datos_originales[(datos_originales >= min_val) & (datos_originales <= max_val)]\n",
    "        excluidos = len(datos_originales) - len(datos)\n",
    "        pct_excluidos = (excluidos / len(datos_originales)) * 100\n",
    "    else:\n",
    "        datos = datos_originales\n",
    "        excluidos = 0\n",
    "        pct_excluidos = 0\n",
    "    \n",
    "    if len(datos) == 0:\n",
    "        print(f\"⚠️  {variable}: Todos los datos fueron filtrados\")\n",
    "        continue\n",
    "    \n",
    "    # Determina número apropiado de bins según el rango\n",
    "    n_unicos = datos.nunique()\n",
    "    if n_unicos <= 25:\n",
    "        n_bins = n_unicos  # Para variables discretas con pocos valores\n",
    "    else:\n",
    "        n_bins = min(50, int(np.sqrt(len(datos))))  # Regla de Sturges ajustada\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle(f'Análisis de Distribución: {variable} (n={len(datos):,})', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Histograma con curva de densidad\n",
    "    axes[0].hist(datos, bins=n_bins, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0].set_xlabel(variable, fontsize=11)\n",
    "    axes[0].set_ylabel('Densidad', fontsize=11)\n",
    "    axes[0].set_title('Histograma', fontsize=12)\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Añade curva normal teórica\n",
    "    mu, sigma = datos.mean(), datos.std()\n",
    "    x = np.linspace(datos.min(), datos.max(), 100)\n",
    "    axes[0].plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, label='Normal teórica')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # 2. Q-Q Plot\n",
    "    stats.probplot(datos.sample(min(10000, len(datos)), random_state=42), dist=\"norm\", plot=axes[1])\n",
    "    axes[1].set_title('Q-Q Plot', fontsize=12)\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Boxplot\n",
    "    axes[2].boxplot(datos, vert=True)\n",
    "    axes[2].set_ylabel(variable, fontsize=11)\n",
    "    axes[2].set_title('Boxplot', fontsize=12)\n",
    "    axes[2].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Guarda gráfico - INCISO B\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Muestra estadísticas\n",
    "    print(f\"\\nEstadísticas de {variable}:\")\n",
    "    print(f\"   • Total datos originales: {len(datos_originales):,}\")\n",
    "    if excluidos > 0:\n",
    "        print(f\"   • Datos excluidos (fuera de rango válido): {excluidos:,} ({pct_excluidos:.2f}%)\")\n",
    "        print(f\"   • Rango válido aplicado: [{rangos_validos[variable][0]}, {rangos_validos[variable][1]}]\")\n",
    "    print(f\"   • Datos válidos analizados: {len(datos):,}\")\n",
    "    print(f\"   • Rango real: [{datos.min():.0f}, {datos.max():.0f}]\")\n",
    "    print(f\"   • Media: {datos.mean():.2f}\")\n",
    "    print(f\"   • Mediana: {datos.median():.2f}\")\n",
    "    print(f\"   • Desv. Estándar: {datos.std():.2f}\")\n",
    "    \n",
    "    info = df_normalidad[df_normalidad['Variable'] == variable]\n",
    "    if not info.empty:\n",
    "        print(f\"   • Asimetría: {info['Asimetría'].values[0]}\")\n",
    "        print(f\"   • Curtosis: {info['Curtosis'].values[0]}\")\n",
    "        print(f\"   • ¿Es normal?: {info['Es_Normal'].values[0]}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db264d0",
   "metadata": {},
   "source": [
    "## 5. Identificación del Tipo de Distribución\n",
    "\n",
    "Para las variables que NO siguen distribución normal, identificamos qué tipo de distribución podrían seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa912d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identificar_distribucion(variable, datos):\n",
    "    \"\"\"\n",
    "    Identifica el tipo de distribución basándose en asimetría, curtosis y pruebas estadísticas\n",
    "    \"\"\"\n",
    "    asimetria = datos.skew()\n",
    "    curtosis = datos.kurtosis()\n",
    "    \n",
    "    tipo_distribucion = []\n",
    "    \n",
    "    # Análisis basado en asimetría y curtosis\n",
    "    if abs(asimetria) < 0.5 and abs(curtosis) < 0.5:\n",
    "        tipo_distribucion.append(\"Normal\")\n",
    "    \n",
    "    if asimetria > 1:\n",
    "        tipo_distribucion.append(\"Sesgada a la derecha (exponencial/log-normal)\")\n",
    "    elif asimetria < -1:\n",
    "        tipo_distribucion.append(\"Sesgada a la izquierda\")\n",
    "    \n",
    "    if curtosis > 3:\n",
    "        tipo_distribucion.append(\"Leptocúrtica (colas pesadas)\")\n",
    "    elif curtosis < -3:\n",
    "        tipo_distribucion.append(\"Platicúrtica (colas ligeras)\")\n",
    "    \n",
    "    # Verifica si es discreta uniforme (valores únicos limitados distribuidos uniformemente)\n",
    "    valores_unicos = datos.nunique()\n",
    "    if valores_unicos <= 50:\n",
    "        freq = datos.value_counts()\n",
    "        coef_var_freq = freq.std() / freq.mean() if freq.mean() > 0 else float('inf')\n",
    "        if coef_var_freq < 0.3:\n",
    "            tipo_distribucion.append(\"Uniforme discreta\")\n",
    "    \n",
    "    # Verifica si puede ser Poisson (datos discretos, asimetría positiva)\n",
    "    if datos.dtype in ['int64', 'float64'] and asimetria > 0 and all(datos == datos.astype(int)):\n",
    "        media = datos.mean()\n",
    "        varianza = datos.var()\n",
    "        if abs(media - varianza) / max(media, 1) < 0.5:\n",
    "            tipo_distribucion.append(\"Poisson\")\n",
    "    \n",
    "    return tipo_distribucion if tipo_distribucion else [\"Distribución desconocida o compleja\"]\n",
    "\n",
    "# Analiza variables no normales\n",
    "print(\"=\"*100)\n",
    "print(\"CLASIFICACIÓN DE DISTRIBUCIONES - VARIABLES NO NORMALES\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "clasificacion_distribuciones = []\n",
    "\n",
    "for variable in variables_numericas:\n",
    "    datos = df_unificado[variable].dropna()\n",
    "    \n",
    "    if len(datos) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Obtiene info de normalidad\n",
    "    info_norm = df_normalidad[df_normalidad['Variable'] == variable]\n",
    "    es_normal = info_norm['Es_Normal'].values[0] if not info_norm.empty else 'No'\n",
    "    \n",
    "    if es_normal == 'No':\n",
    "        tipos = identificar_distribucion(variable, datos)\n",
    "        asimetria = datos.skew()\n",
    "        curtosis = datos.kurtosis()\n",
    "        \n",
    "        clasificacion_distribuciones.append({\n",
    "            'Variable': variable,\n",
    "            'Valores_Únicos': datos.nunique(),\n",
    "            'Asimetría': f\"{asimetria:.2f}\",\n",
    "            'Curtosis': f\"{curtosis:.2f}\",\n",
    "            'Tipo_Distribución_Sugerida': ', '.join(tipos)\n",
    "        })\n",
    "\n",
    "df_distribuciones = pd.DataFrame(clasificacion_distribuciones)\n",
    "display(df_distribuciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d92e1a",
   "metadata": {},
   "source": [
    "## 6. Análisis de Variables Categóricas - Tablas de Frecuencia\n",
    "\n",
    "Para cada variable categórica, generamos tablas de frecuencia que muestran:\n",
    "- Conteo absoluto\n",
    "- Porcentaje\n",
    "- Top categorías más frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dee1e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"TABLAS DE FRECUENCIA - VARIABLES CATEGÓRICAS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Diccionario para almacenar todas las tablas de frecuencia\n",
    "tablas_frecuencia = {}\n",
    "\n",
    "for variable in variables_categoricas:\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Variable: {variable}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Calcula frecuencias\n",
    "    frecuencias = df_unificado[variable].value_counts()\n",
    "    porcentajes = df_unificado[variable].value_counts(normalize=True) * 100\n",
    "    \n",
    "    # Crea tabla combinada\n",
    "    tabla_freq = pd.DataFrame({\n",
    "        'Categoría': frecuencias.index,\n",
    "        'Frecuencia': frecuencias.values,\n",
    "        'Porcentaje': porcentajes.values\n",
    "    })\n",
    "    \n",
    "    tabla_freq['Porcentaje'] = tabla_freq['Porcentaje'].round(2)\n",
    "    \n",
    "    # Guarda en diccionario\n",
    "    tablas_frecuencia[variable] = tabla_freq\n",
    "    \n",
    "    # Muestra información general\n",
    "    print(f\"Total de categorías únicas: {len(tabla_freq)}\")\n",
    "    print(f\"Valores nulos: {df_unificado[variable].isna().sum()} ({df_unificado[variable].isna().sum()/len(df_unificado)*100:.2f}%)\")\n",
    "    \n",
    "    # Muestra top 20 categorías\n",
    "    print(f\"\\nTop 20 categorías más frecuentes:\")\n",
    "    display(tabla_freq.head(20))\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"Se generaron {len(tablas_frecuencia)} tablas de frecuencia\")\n",
    "print(f\"{'='*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dde90f",
   "metadata": {},
   "source": [
    "## 7. Visualización de Variables Categóricas Clave\n",
    "\n",
    "Visualizamos las variables categóricas más relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona variables categóricas más importantes para visualizar\n",
    "# (limitamos a las primeras o las que tienen menos categorías para mejor visualización)\n",
    "\n",
    "variables_cat_visualizar = []\n",
    "\n",
    "for var in variables_categoricas:\n",
    "    n_categorias = df_unificado[var].nunique()\n",
    "    if n_categorias <= 50:  # Solo visualizar si tiene 50 o menos categorías\n",
    "        variables_cat_visualizar.append((var, n_categorias))\n",
    "\n",
    "# Ordena por número de categorías\n",
    "variables_cat_visualizar.sort(key=lambda x: x[1])\n",
    "\n",
    "print(f\"Visualizando {min(len(variables_cat_visualizar), 6)} variables categóricas:\\n\")\n",
    "\n",
    "# Visualizar hasta 6 variables categóricas\n",
    "for idx, (var, n_cat) in enumerate(variables_cat_visualizar[:6], start=1):\n",
    "    # Obtiene top 15 categorías\n",
    "    top_categorias = df_unificado[var].value_counts().head(15)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    fig.suptitle(f'Distribución de: {var} ({n_cat} categorías únicas)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Gráfico de barras\n",
    "    ax.barh(range(len(top_categorias)), top_categorias.values, color='steelblue')\n",
    "    ax.set_yticks(range(len(top_categorias)))\n",
    "    ax.set_yticklabels([str(cat)[:30] for cat in top_categorias.index])  # Limitar longitud de etiquetas\n",
    "    ax.set_xlabel('Frecuencia')\n",
    "    ax.set_title(f'Top 15 Categorías - Frecuencia Absoluta')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Guarda gráfico - INCISO B\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nVariable: {var}\")\n",
    "    print(f\"  - Categorías únicas: {n_cat}\")\n",
    "    print(f\"  - Valores nulos: {df_unificado[var].isna().sum()} ({df_unificado[var].isna().sum()/len(df_unificado)*100:.2f}%)\")\n",
    "    print(f\"  - Categoría más frecuente: {top_categorias.index[0]} ({top_categorias.values[0]} casos, {top_categorias.values[0]/len(df_unificado)*100:.2f}%)\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd5ed06",
   "metadata": {},
   "source": [
    "## 8. Resumen de Variables Numéricas Discretas (Categóricas Numéricas)\n",
    "\n",
    "Algunas variables numéricas son en realidad categóricas (como Sexo, Mes, etc.). Generamos tablas de frecuencia para estas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed031c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables numéricas que son en realidad categóricas\n",
    "variables_num_categoricas = []\n",
    "\n",
    "for var in variables_numericas:\n",
    "    n_unicos = df_unificado[var].nunique()\n",
    "    if n_unicos <= 50:  # Si tiene 50 o menos valores únicos, es categórica\n",
    "        variables_num_categoricas.append((var, n_unicos))\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"VARIABLES NUMÉRICAS DISCRETAS (TRATADAS COMO CATEGÓRICAS)\")\n",
    "print(\"=\"*100)\n",
    "print(f\"\\nSe identificaron {len(variables_num_categoricas)} variables numéricas discretas:\\n\")\n",
    "\n",
    "for idx, (var, n_unicos) in enumerate(variables_num_categoricas, start=1):\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"Variable: {var} ({n_unicos} valores únicos)\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Tabla de frecuencia\n",
    "    frecuencias = df_unificado[var].value_counts().sort_index()\n",
    "    porcentajes = (frecuencias / len(df_unificado) * 100).round(2)\n",
    "    \n",
    "    tabla = pd.DataFrame({\n",
    "        'Valor': frecuencias.index,\n",
    "        'Frecuencia': frecuencias.values,\n",
    "        'Porcentaje': porcentajes.values\n",
    "    })\n",
    "    \n",
    "    display(tabla)\n",
    "    \n",
    "    # Visualización\n",
    "    if n_unicos <= 20:  # Solo graficar si no son demasiados valores\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        fig.suptitle(f'Distribución de: {var}', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Gráfico de barras con frecuencia\n",
    "        ax.bar(tabla['Valor'].astype(str), tabla['Frecuencia'], color='teal', alpha=0.7)\n",
    "        ax.set_xlabel('Valor', fontsize=11)\n",
    "        ax.set_ylabel('Frecuencia', fontsize=11)\n",
    "        ax.set_title('Frecuencia por Valor', fontsize=12, fontweight='bold')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Guarda gráfico - INCISO B\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "print(f\"\\n{'='*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5217c28b",
   "metadata": {},
   "source": [
    "## Conclusiones del Inciso b\n",
    "\n",
    "### Hallazgos principales del análisis estadístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288676c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"CONCLUSIONES - INCISO B: ANÁLISIS ESTADÍSTICO DE VARIABLES\")\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "\n",
    "# 1. Resumen de normalidad\n",
    "print(\"1. DISTRIBUCIÓN NORMAL DE VARIABLES NUMÉRICAS:\")\n",
    "print(\"-\" * 80)\n",
    "if 'df_normalidad' in locals():\n",
    "    normal_vars = df_normalidad[df_normalidad['Es_Normal'] == 'Sí']\n",
    "    no_normal_vars = df_normalidad[df_normalidad['Es_Normal'] == 'No']\n",
    "    \n",
    "    print(f\"   Total de variables numéricas analizadas: {len(df_normalidad)}\")\n",
    "    print(f\"   Variables con distribución NORMAL: {len(normal_vars)} ({len(normal_vars)/len(df_normalidad)*100:.1f}%)\")\n",
    "    print(f\"   Variables con distribución NO NORMAL: {len(no_normal_vars)} ({len(no_normal_vars)/len(df_normalidad)*100:.1f}%)\")\n",
    "    \n",
    "    if len(normal_vars) > 0:\n",
    "        print(f\"\\n   Variables normales: {', '.join(normal_vars['Variable'].tolist())}\")\n",
    "print()\n",
    "\n",
    "# 2. Tipos de distribución encontradas\n",
    "print(\"2. TIPOS DE DISTRIBUCIONES IDENTIFICADAS:\")\n",
    "print(\"-\" * 80)\n",
    "if 'df_distribuciones' in locals() and len(df_distribuciones) > 0:\n",
    "    print(\"   La mayoría de variables muestran distribuciones:\")\n",
    "    print(\"   - Sesgadas a la derecha (asimetría positiva)\")\n",
    "    print(\"   - Leptocúrticas (colas pesadas, curtosis alta)\")\n",
    "    print(\"   - Algunas presentan distribuciones uniformes discretas\")\n",
    "    print(\"   - Distribuciones tipo Poisson en variables de conteo\")\n",
    "    \n",
    "    # Muestra resumen de asimetrías\n",
    "    asimetrias_positivas = sum(1 for _, row in df_distribuciones.iterrows() if float(row['Asimetría']) > 0)\n",
    "    asimetrias_negativas = sum(1 for _, row in df_distribuciones.iterrows() if float(row['Asimetría']) < 0)\n",
    "    \n",
    "    print(f\"\\n   Asimetría positiva (sesgadas derecha): {asimetrias_positivas} variables\")\n",
    "    print(f\"   Asimetría negativa (sesgadas izquierda): {asimetrias_negativas} variables\")\n",
    "print()\n",
    "\n",
    "# 3. Variables categóricas\n",
    "print(\"3. VARIABLES CATEGÓRICAS:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"   Total de variables categóricas (tipo object): {len(variables_categoricas)}\")\n",
    "if len(variables_categoricas) > 0:\n",
    "    print(f\"   Variables: {', '.join(variables_categoricas)}\")\n",
    "print()\n",
    "\n",
    "# 4. Variables numéricas discretas\n",
    "print(\"4. VARIABLES NUMÉRICAS DISCRETAS (CATEGÓRICAS NUMÉRICAS):\")\n",
    "print(\"-\" * 80)\n",
    "if 'variables_num_categoricas' in locals():\n",
    "    print(f\"   Se identificaron {len(variables_num_categoricas)} variables numéricas con valores discretos\")\n",
    "    print(f\"   Estas incluyen: {', '.join([v[0] for v in variables_num_categoricas[:10]])}\")\n",
    "print()\n",
    "\n",
    "# 5. Archivos generados\n",
    "print(\"5. ARCHIVOS GENERADOS PARA DOCUMENTACIÓN:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"   resumen_estadistico_numericas.csv - Estadísticas descriptivas completas\")\n",
    "print(\"   pruebas_normalidad.csv - Resultados de tests de normalidad\")\n",
    "print(\"   clasificacion_distribuciones.csv - Tipos de distribución identificados\")\n",
    "print(\"   frecuencia_[variable].csv - Tablas de frecuencia individuales\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"RECOMENDACIONES:\")\n",
    "print(\"=\"*100)\n",
    "print(\"• Las variables NO siguen distribución normal en su mayoría\")\n",
    "print(\"• Se recomienda usar estadísticas robustas (mediana, IQR) en lugar de media/desv.std\")\n",
    "print(\"• Para análisis inferencial, considerar transformaciones (log, sqrt) o métodos no paramétricos\")\n",
    "print(\"• Muchas variables tienen valores faltantes significativos - considerar imputación o análisis de sesgo\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39528f66",
   "metadata": {},
   "source": [
    "# INCISO C: Identificación de Variables Clave\n",
    "\n",
    "## Problema a Investigar:\n",
    "**\"Matrimonios que terminan en problemas de violencia intrafamiliar y en muertes por violencia\"**\n",
    "\n",
    "En esta sección identificaremos las variables del dataset de defunciones que son relevantes para cruzar con los datos de matrimonios y violencia intrafamiliar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e90a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS DE VARIABLES RELEVANTES PARA EL PROBLEMA:\n",
    "# \"Matrimonios que terminan en violencia intrafamiliar y que termine en defunciones por violencia\"\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"IDENTIFICACIÓN DE VARIABLES CLAVE PARA CRUCES DE DATOS\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\nProblema a investigar:\")\n",
    "print(\"'Matrimonios que terminan en violencia intrafamiliar y que termine en defunciones por violencia'\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Primero, exploramos las variables disponibles en el dataset\n",
    "print(\"\\n1. EXPLORANDO VARIABLES DEL DATASET DE DEFUNCIONES\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Muestra todas las variables disponibles\n",
    "print(\"\\nVariables disponibles en el dataset:\")\n",
    "for i, col in enumerate(df_unificado.columns, 1):\n",
    "    descripcion = df_resumen[df_resumen['Variable'] == col]['Descripción'].values\n",
    "    desc_text = descripcion[0] if len(descripcion) > 0 else 'Sin descripción'\n",
    "    print(f\"{i:2d}. {col:20s} - {desc_text}\")\n",
    "\n",
    "print(f\"\\n{'='*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6143c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. IDENTIFICAR VARIABLES RELACIONADAS CON VIOLENCIA\n",
    "print(\"\\n2. BÚSQUEDA DE VARIABLES RELACIONADAS CON VIOLENCIA\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Busca columnas que contengan palabras clave relacionadas con violencia\n",
    "keywords_violencia = ['viol', 'homi', 'muerte', 'causa', 'manera', 'lesion', 'agres']\n",
    "\n",
    "variables_violencia = []\n",
    "\n",
    "for col in df_unificado.columns:\n",
    "    col_lower = col.lower()\n",
    "    descripcion = df_resumen[df_resumen['Variable'] == col]['Descripción'].values\n",
    "    desc_text = (descripcion[0] if len(descripcion) > 0 else '').lower()\n",
    "    \n",
    "    # Busca en nombre de columna o descripción\n",
    "    for keyword in keywords_violencia:\n",
    "        if keyword in col_lower or keyword in desc_text:\n",
    "            variables_violencia.append({\n",
    "                'Variable': col,\n",
    "                'Descripción': descripcion[0] if len(descripcion) > 0 else 'Sin descripción',\n",
    "                'Valores_Únicos': df_unificado[col].nunique(),\n",
    "                'Tipo': df_resumen[df_resumen['Variable'] == col]['Tipo'].values[0] if len(df_resumen[df_resumen['Variable'] == col]) > 0 else 'N/A'\n",
    "            })\n",
    "            break\n",
    "\n",
    "df_vars_violencia = pd.DataFrame(variables_violencia)\n",
    "\n",
    "if len(df_vars_violencia) > 0:\n",
    "    print(f\"\\nSe encontraron {len(df_vars_violencia)} variables relacionadas con violencia:\\n\")\n",
    "    display(df_vars_violencia)\n",
    "else:\n",
    "    print(\"\\nNo se encontraron variables con las palabras clave de violencia.\")\n",
    "    print(\"Explorando variables de 'causa' y 'manera' de muerte...\")\n",
    "\n",
    "print(f\"\\n{'='*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad69de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. IDENTIFICAR VARIABLES DEMOGRÁFICAS Y DE ESTADO CIVIL\n",
    "print(\"\\n3. VARIABLES DEMOGRÁFICAS Y DE ESTADO CIVIL\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Busca variables relacionadas con estado civil, edad, sexo, etc.\n",
    "keywords_demograficas = ['edad', 'sex', 'civil', 'matrim', 'espos', 'casad', 'solter', 'union']\n",
    "\n",
    "variables_demograficas = []\n",
    "\n",
    "for col in df_unificado.columns:\n",
    "    col_lower = col.lower()\n",
    "    descripcion = df_resumen[df_resumen['Variable'] == col]['Descripción'].values\n",
    "    desc_text = (descripcion[0] if len(descripcion) > 0 else '').lower()\n",
    "    \n",
    "    for keyword in keywords_demograficas:\n",
    "        if keyword in col_lower or keyword in desc_text:\n",
    "            variables_demograficas.append({\n",
    "                'Variable': col,\n",
    "                'Descripción': descripcion[0] if len(descripcion) > 0 else 'Sin descripción',\n",
    "                'Valores_Únicos': df_unificado[col].nunique(),\n",
    "                'Tipo': df_resumen[df_resumen['Variable'] == col]['Tipo'].values[0] if len(df_resumen[df_resumen['Variable'] == col]) > 0 else 'N/A'\n",
    "            })\n",
    "            break\n",
    "\n",
    "df_vars_demograficas = pd.DataFrame(variables_demograficas)\n",
    "\n",
    "if len(df_vars_demograficas) > 0:\n",
    "    print(f\"\\nSe encontraron {len(df_vars_demograficas)} variables demográficas relevantes:\\n\")\n",
    "    display(df_vars_demograficas)\n",
    "else:\n",
    "    print(\"\\nNo se encontraron variables demográficas con las palabras clave especificadas.\")\n",
    "\n",
    "print(f\"\\n{'='*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. IDENTIFICAR VARIABLES GEOGRÁFICAS Y TEMPORALES\n",
    "print(\"\\n4. VARIABLES GEOGRÁFICAS Y TEMPORALES\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Busca variables relacionadas con ubicación y tiempo\n",
    "keywords_geo_temp = ['dep', 'mun', 'lugar', 'mes', 'año', 'anio', 'fecha', 'regi']\n",
    "\n",
    "variables_geo_temp = []\n",
    "\n",
    "for col in df_unificado.columns:\n",
    "    col_lower = col.lower()\n",
    "    descripcion = df_resumen[df_resumen['Variable'] == col]['Descripción'].values\n",
    "    desc_text = (descripcion[0] if len(descripcion) > 0 else '').lower()\n",
    "    \n",
    "    for keyword in keywords_geo_temp:\n",
    "        if keyword in col_lower or keyword in desc_text:\n",
    "            variables_geo_temp.append({\n",
    "                'Variable': col,\n",
    "                'Descripción': descripcion[0] if len(descripcion) > 0 else 'Sin descripción',\n",
    "                'Valores_Únicos': df_unificado[col].nunique(),\n",
    "                'Tipo': df_resumen[df_resumen['Variable'] == col]['Tipo'].values[0] if len(df_resumen[df_resumen['Variable'] == col]) > 0 else 'N/A'\n",
    "            })\n",
    "            break\n",
    "\n",
    "df_vars_geo_temp = pd.DataFrame(variables_geo_temp)\n",
    "\n",
    "if len(df_vars_geo_temp) > 0:\n",
    "    print(f\"\\nSe encontraron {len(df_vars_geo_temp)} variables geográficas/temporales:\\n\")\n",
    "    display(df_vars_geo_temp)\n",
    "else:\n",
    "    print(\"\\nNo se encontraron variables geográficas/temporales.\")\n",
    "\n",
    "print(f\"\\n{'='*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d4695",
   "metadata": {},
   "source": [
    "## 5. Variables Clave Identificadas para Cruces de Datos\n",
    "\n",
    "Con base en el problema investigado, se han identificado las siguientes categorías de variables clave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e24fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. RESUMEN DE VARIABLES CLAVE PARA CRUCE DE DATOS\n",
    "print(\"=\"*100)\n",
    "print(\"RESUMEN: VARIABLES CLAVE PARA ANÁLISIS DE VIOLENCIA INTRAFAMILIAR Y DEFUNCIONES\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Consolidar todas las variables identificadas\n",
    "variables_clave_final = {\n",
    "    'Violencia y Causa de Muerte': df_vars_violencia if len(df_vars_violencia) > 0 else pd.DataFrame(),\n",
    "    'Demográficas y Estado Civil': df_vars_demograficas if len(df_vars_demograficas) > 0 else pd.DataFrame(),\n",
    "    'Geográficas y Temporales': df_vars_geo_temp if len(df_vars_geo_temp) > 0 else pd.DataFrame()\n",
    "}\n",
    "\n",
    "print(\"\\nVARIABLES CLAVE IDENTIFICADAS POR CATEGORÍA:\\n\")\n",
    "\n",
    "total_variables = 0\n",
    "for categoria, df_cat in variables_clave_final.items():\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"CATEGORÍA: {categoria}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    if len(df_cat) > 0:\n",
    "        print(f\"\\nSe encontraron {len(df_cat)} variables en esta categoría:\\n\")\n",
    "        display(df_cat)\n",
    "        total_variables += len(df_cat)\n",
    "    else:\n",
    "        print(\"\\nNo se encontraron variables en esta categoría con los criterios de búsqueda.\\n\")\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"TOTAL DE VARIABLES CLAVE IDENTIFICADAS: {total_variables}\")\n",
    "print(f\"{'='*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bffb2eb",
   "metadata": {},
   "source": [
    "## 6. Propuesta de Cruces de Variables\n",
    "\n",
    "Para investigar el problema de \"Matrimonios que terminan en violencia intrafamiliar y defunciones por violencia\", se proponen los siguientes cruces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f7173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. PROPUESTA DE CRUCES DE VARIABLES\n",
    "print(\"=\"*100)\n",
    "print(\"PROPUESTA DE CRUCES DE VARIABLES PARA EL ANÁLISIS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "propuesta_cruces = \"\"\"\n",
    "Para investigar 'Matrimonios que terminan en violencia intrafamiliar y defunciones por violencia',\n",
    "se proponen los siguientes cruces de variables:\n",
    "\n",
    "CRUCES PRINCIPALES:\n",
    "\n",
    "1. ESTADO CIVIL × CAUSA DE MUERTE\n",
    "   - Objetivo: Identificar defunciones violentas por estado civil\n",
    "   - Variables clave: Estado civil (casado/unión libre) × Causas violentas\n",
    "   - Hipótesis: Personas casadas/en unión tienen más probabilidad de muerte por violencia intrafamiliar\n",
    "\n",
    "2. SEXO × CAUSA DE MUERTE × ESTADO CIVIL\n",
    "   - Objetivo: Identificar el género más afectado en contextos de violencia doméstica\n",
    "   - Variables clave: Sexo × Causa violenta × Estado civil\n",
    "   - Hipótesis: Las mujeres casadas tienen mayor riesgo de defunción por violencia intrafamiliar\n",
    "\n",
    "3. EDAD × ESTADO CIVIL × CAUSA DE MUERTE\n",
    "   - Objetivo: Identificar rangos etarios de mayor riesgo\n",
    "   - Variables clave: Edad (grupos) × Estado civil × Causas violentas\n",
    "   - Hipótesis: Ciertos grupos etarios son más vulnerables a violencia en matrimonios\n",
    "\n",
    "4. UBICACIÓN GEOGRÁFICA × ESTADO CIVIL × CAUSA DE MUERTE\n",
    "   - Objetivo: Mapear zonas con mayor incidencia de violencia intrafamiliar fatal\n",
    "   - Variables clave: Departamento/Municipio × Estado civil × Causas violentas\n",
    "   - Hipótesis: Áreas específicas tienen mayor concentración de casos\n",
    "\n",
    "5. TENDENCIA TEMPORAL × ESTADO CIVIL × CAUSA DE MUERTE\n",
    "   - Objetivo: Identificar evolución del problema a lo largo del tiempo\n",
    "   - Variables clave: Año/Mes × Estado civil × Causas violentas\n",
    "   - Hipótesis: La violencia intrafamiliar fatal ha aumentado/disminuido en años recientes\n",
    "\n",
    "6. MANERA DE MUERTE × ESTADO CIVIL\n",
    "   - Objetivo: Identificar la forma en que ocurren las muertes (homicidio, suicidio, accidente)\n",
    "   - Variables clave: Manera de muerte × Estado civil\n",
    "   - Hipótesis: Homicidios predominan en contextos de violencia intrafamiliar\n",
    "\n",
    "CRUCES COMPLEMENTARIOS:\n",
    "\n",
    "7. OCUPACIÓN × ESTADO CIVIL × CAUSA DE MUERTE\n",
    "   - Objetivo: Identificar perfiles ocupacionales de víctimas\n",
    "   \n",
    "8. NIVEL EDUCATIVO × ESTADO CIVIL × CAUSA DE MUERTE (si disponible)\n",
    "   - Objetivo: Analizar relación entre educación y violencia intrafamiliar\n",
    "   \n",
    "9. ÁREA (URBANA/RURAL) × ESTADO CIVIL × CAUSA DE MUERTE\n",
    "   - Objetivo: Comparar incidencia entre áreas urbanas y rurales\n",
    "\n",
    "VARIABLES DE ENLACE ENTRE DATASETS:\n",
    "\n",
    "Para cruzar con datos de MATRIMONIOS y VIOLENCIA INTRAFAMILIAR:\n",
    "- Año (ANIO)\n",
    "- Departamento de registro/ocurrencia\n",
    "- Municipio de registro/ocurrencia\n",
    "- Sexo\n",
    "- Edad (para crear cohortes)\n",
    "- Estado civil\n",
    "\n",
    "Para cruzar con VIOLENCIA INTRAFAMILIAR:\n",
    "- Año\n",
    "- Departamento\n",
    "- Municipio\n",
    "- Edad\n",
    "- Sexo\n",
    "- Tipo de relación con agresor (si existe variable equivalente en defunciones)\n",
    "\"\"\"\n",
    "\n",
    "print(propuesta_cruces)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"RECOMENDACIONES PARA EL ANÁLISIS:\")\n",
    "print(\"=\"*100)\n",
    "print(\"\"\"\n",
    "1. Filtrar defunciones por causas relacionadas con violencia (homicidios, lesiones)\n",
    "2. Crear subconjunto de personas casadas/en unión libre\n",
    "3. Analizar patrones geográficos para identificar hotspots\n",
    "4. Comparar tasas de defunciones violentas entre diferentes estados civiles\n",
    "5. Utilizar análisis de series temporales para identificar tendencias\n",
    "6. Realizar análisis bivariado y multivariado con las variables identificadas\n",
    "7. Considerar factores confusores (edad, ubicación, contexto socioeconómico)\n",
    "8. Validar hipótesis con pruebas estadísticas apropiadas (Chi-cuadrado, regresión logística)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da034439",
   "metadata": {},
   "source": [
    "## 7. Exploración Inicial de Variables Clave\n",
    "\n",
    "Realizaremos un análisis exploratorio de las variables más relevantes para el estudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9183cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. EXPLORACIÓN DETALLADA DE VARIABLES CLAVE ESPECÍFICAS\n",
    "print(\"=\"*100)\n",
    "print(\"ANÁLISIS EXPLORATORIO DE VARIABLES CLAVE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Lista de variables que probablemente existen en el dataset y son relevantes\n",
    "variables_a_explorar = []\n",
    "\n",
    "# Variables comunes en datasets de defunciones\n",
    "variables_posibles = {\n",
    "    'Sexo': 'Sexo de la persona fallecida',\n",
    "    'Edadif': 'Edad de la persona al fallecer',\n",
    "    'EstCiv': 'Estado civil',\n",
    "    'Estciv': 'Estado civil',\n",
    "    'ESTCIV': 'Estado civil',\n",
    "    'Depreg': 'Departamento de registro',\n",
    "    'Depocu': 'Departamento de ocurrencia',\n",
    "    'Munreg': 'Municipio de registro',\n",
    "    'Munocu': 'Municipio de ocurrencia',\n",
    "    'Mesreg': 'Mes de registro',\n",
    "    'Mesocu': 'Mes de ocurrencia',\n",
    "    'ANIO': 'Año',\n",
    "    'Causadef': 'Causa de defunción',\n",
    "    'Causa': 'Causa',\n",
    "    'Manera': 'Manera de muerte',\n",
    "    'Area': 'Área (urbana/rural)',\n",
    "    'AREA': 'Área (urbana/rural)'\n",
    "}\n",
    "\n",
    "# Verifica cuáles variables existen realmente en el dataset\n",
    "for var, desc in variables_posibles.items():\n",
    "    if var in df_unificado.columns:\n",
    "        variables_a_explorar.append({\n",
    "            'Variable': var,\n",
    "            'Descripción': desc,\n",
    "            'Existe': True\n",
    "        })\n",
    "\n",
    "df_vars_explorar = pd.DataFrame(variables_a_explorar)\n",
    "\n",
    "print(f\"\\nVariables identificadas para exploración ({len(df_vars_explorar)} encontradas):\\n\")\n",
    "if len(df_vars_explorar) > 0:\n",
    "    display(df_vars_explorar)\n",
    "else:\n",
    "    print(\"No se encontraron las variables esperadas. Mostrando todas las variables disponibles:\")\n",
    "    print(\"\\nVariables disponibles en el dataset:\")\n",
    "    for col in df_unificado.columns[:20]:  # Muestra las primeras 20\n",
    "        print(f\"  - {col}\")\n",
    "    if len(df_unificado.columns) > 20:\n",
    "        print(f\"  ... y {len(df_unificado.columns) - 20} más\")\n",
    "\n",
    "print(f\"\\n{'='*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb06b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. ANÁLISIS DE DISTRIBUCIONES DE VARIABLES CLAVE ENCONTRADAS\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ANÁLISIS DE DISTRIBUCIONES - VARIABLES CLAVE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Analiza cada variable encontrada\n",
    "for var in df_vars_explorar['Variable'].tolist() if len(df_vars_explorar) > 0 else []:\n",
    "    if var in df_unificado.columns:\n",
    "        print(f\"\\n{'─'*100}\")\n",
    "        print(f\"Variable: {var}\")\n",
    "        print(f\"{'─'*100}\")\n",
    "        \n",
    "        # Información básica\n",
    "        n_total = len(df_unificado[var])\n",
    "        n_unicos = df_unificado[var].nunique()\n",
    "        n_missing = df_unificado[var].isna().sum()\n",
    "        pct_missing = (n_missing / n_total) * 100\n",
    "        \n",
    "        print(f\"\\nEstadísticas básicas:\")\n",
    "        print(f\"   - Total de registros: {n_total:,}\")\n",
    "        print(f\"   - Valores únicos: {n_unicos:,}\")\n",
    "        print(f\"   - Valores faltantes: {n_missing:,} ({pct_missing:.2f}%)\")\n",
    "        \n",
    "        # Si tiene pocos valores únicos, mostrar distribución\n",
    "        if n_unicos <= 100 and n_unicos > 0:\n",
    "            print(f\"\\nDistribución de valores (Top 20):\")\n",
    "            freq = df_unificado[var].value_counts().head(20)\n",
    "            freq_df = pd.DataFrame({\n",
    "                'Valor': freq.index,\n",
    "                'Frecuencia': freq.values,\n",
    "                'Porcentaje': (freq.values / n_total * 100).round(2)\n",
    "            })\n",
    "            display(freq_df)\n",
    "        elif n_unicos > 100:\n",
    "            print(f\"\\n   → Variable con muchos valores únicos ({n_unicos}). Mostrando estadísticas:\")\n",
    "            if df_unificado[var].dtype in ['int64', 'float64']:\n",
    "                stats_desc = df_unificado[var].describe()\n",
    "                print(f\"      Media: {stats_desc['mean']:.2f}\")\n",
    "                print(f\"      Mediana: {stats_desc['50%']:.2f}\")\n",
    "                print(f\"      Desv. Estándar: {stats_desc['std']:.2f}\")\n",
    "                print(f\"      Mínimo: {stats_desc['min']:.2f}\")\n",
    "                print(f\"      Máximo: {stats_desc['max']:.2f}\")\n",
    "\n",
    "print(f\"\\n{'='*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0677f0",
   "metadata": {},
   "source": [
    "## Conclusiones del Inciso C\n",
    "\n",
    "### Variables Clave Identificadas y Estrategia de Cruces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93066be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"CONCLUSIONES - INCISO C: VARIABLES CLAVE PARA CRUCES DE DATOS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "conclusiones_c = \"\"\"\n",
    "OBJETIVO DEL ANÁLISIS:\n",
    "   Identificar las variables clave del dataset de defunciones que permitan investigar el problema:\n",
    "   \"Matrimonios que terminan en violencia intrafamiliar y que termine en defunciones por violencia\"\n",
    "\n",
    "VARIABLES CLAVE IDENTIFICADAS:\n",
    "\n",
    "1. VARIABLES DE VIOLENCIA/CAUSA:\n",
    "   - Causa de defunción (códigos CIE-10)\n",
    "   - Manera de muerte (homicidio, suicidio, accidente, natural)\n",
    "   - Tipo de lesión/violencia\n",
    "   IMPORTANCIA: Permiten filtrar defunciones por violencia e identificar tipos específicos\n",
    "\n",
    "2. VARIABLES DEMOGRÁFICAS:\n",
    "   - Sexo\n",
    "   - Edad\n",
    "   - Estado civil (casado, unión libre, soltero, divorciado, viudo)\n",
    "   IMPORTANCIA: Identifican perfiles de víctimas y permiten filtrar personas en matrimonios\n",
    "\n",
    "3. VARIABLES GEOGRÁFICAS:\n",
    "   - Departamento de registro/ocurrencia\n",
    "   - Municipio de registro/ocurrencia\n",
    "   - Área (urbana/rural)\n",
    "   IMPORTANCIA: Identifican zonas geográficas de mayor incidencia\n",
    "\n",
    "4. VARIABLES TEMPORALES:\n",
    "   - Año (ANIO)\n",
    "   - Mes de registro/ocurrencia\n",
    "   IMPORTANCIA: Permiten análisis de tendencias y estacionalidad\n",
    "\n",
    "5. VARIABLES COMPLEMENTARIAS:\n",
    "   - Ocupación\n",
    "   - Escolaridad (si disponible)\n",
    "   IMPORTANCIA: Perfilan características socioeconómicas de víctimas\n",
    "\n",
    "ESTRATEGIA DE CRUCES PROPUESTA:\n",
    "\n",
    "PRIMARIOS (para análisis interno del dataset de defunciones):\n",
    "   1. Estado Civil × Causa de Muerte Violenta\n",
    "   2. Sexo × Estado Civil × Causa de Muerte\n",
    "   3. Edad × Estado Civil × Tipo de Violencia\n",
    "   4. Departamento × Estado Civil × Defunciones Violentas\n",
    "   5. Tendencia Temporal × Violencia en Parejas\n",
    "\n",
    "SECUNDARIOS (para cruce con otros datasets):\n",
    "   Con MATRIMONIOS:\n",
    "   - Año + Departamento + Municipio → Comparar tasas de matrimonios vs defunciones\n",
    "   - Cohortes de edad → Analizar grupos etarios en matrimonios y defunciones\n",
    "   \n",
    "   Con VIOLENCIA INTRAFAMILIAR:\n",
    "   - Año + Departamento + Municipio + Sexo → Correlacionar denuncias con defunciones\n",
    "   - Edad + Sexo → Identificar grupos vulnerables\n",
    "   - Tipo de violencia → Vincular con causas de muerte\n",
    "\n",
    "MÉTRICAS Y ANÁLISIS SUGERIDOS:\n",
    "\n",
    "   1. Tasa de defunciones violentas por estado civil\n",
    "   2. Proporción de mujeres vs hombres en defunciones violentas dentro del matrimonio\n",
    "   3. Hotspots geográficos de violencia intrafamiliar fatal\n",
    "   4. Evolución temporal del problema (2009-2020)\n",
    "   5. Análisis de edad y vulnerabilidad\n",
    "   6. Correlación entre causas específicas y estado civil\n",
    "\n",
    "CONSIDERACIONES IMPORTANTES:\n",
    "\n",
    "   1. Los datos de defunciones muestran el resultado final (muerte), no el proceso previo\n",
    "   2. Se necesita cruce con datos de violencia intrafamiliar para identificar casos previos\n",
    "   3. Variables como \"relación con agresor\" pueden no estar en defunciones (buscar en VI)\n",
    "   4. La causa de muerte puede no especificar contexto familiar (requiere análisis detallado)\n",
    "   5. Considerar subregistro y calidad de datos en zonas rurales\n",
    "\n",
    "PRÓXIMOS PASOS RECOMENDADOS:\n",
    "\n",
    "   1. Filtrar dataset por estado civil (casado, unión libre)\n",
    "   2. Filtrar por causas de muerte violentas (homicidios, lesiones)\n",
    "   3. Crear visualizaciones de cruces principales\n",
    "   4. Realizar análisis estadístico (Chi-cuadrado, correlaciones)\n",
    "   5. Cruzar con datasets de matrimonios y violencia intrafamiliar\n",
    "   6. Validar hipótesis con modelos predictivos\n",
    "   7. Generar mapas de calor geográficos\n",
    "   8. Realizar análisis de series temporales\n",
    "\"\"\"\n",
    "\n",
    "print(conclusiones_c)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"INCISO C COMPLETADO\")\n",
    "print(\"=\"*100)\n",
    "print(\"\"\"\n",
    "Se han identificado exitosamente las variables clave del dataset de defunciones\n",
    "que serán fundamentales para investigar el problema de violencia intrafamiliar\n",
    "y su relación con defunciones.\n",
    "\n",
    "Las variables identificadas permitirán realizar cruces significativos tanto\n",
    "dentro del dataset de defunciones como con los datasets de matrimonios y\n",
    "violencia intrafamiliar.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}